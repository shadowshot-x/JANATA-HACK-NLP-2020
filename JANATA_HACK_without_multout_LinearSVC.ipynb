{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JANATA-HACK without multout LinearSVC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqA_LT8zcwNa",
        "colab_type": "text"
      },
      "source": [
        "# **JANATA HACK INDEPENDENCE DAY 2020 ML HACKATHON**\n",
        "\n",
        "Appliaed a Variety of approaches tried and I got a diverse variety of results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7WWh9XXdcE-",
        "colab_type": "text"
      },
      "source": [
        "Models Applied :-\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1.   Deep Learning<br>\n",
        "  *   One Layer CNN Model with GloVe ( 0.8029 ) and without GloVe ( 0.7973 ) \n",
        "  *   One Layer BiLSTM Model with GloVe ( 0.8083 ) without GloVe ( 0.7974 )\n",
        "  *   One Layer BiGRU Model with GloVe ( 0.7924 )\n",
        "\n",
        "  I could not get past this accuracy with Multiple trials and different hyperparameters. Saw an immense jump of models from around 75% to 80% with text cleaning (Helped convergence of loss of the training set and prevent overfitting) \n",
        "\n",
        "---\n",
        "\n",
        "2.   Machine Learning\n",
        "  *   Naive Bayes with CountVectorization ( 0.8028 )\n",
        "  *   Logistic Regression with TFIDF( Word Level ) ( 0.7989 )\n",
        "  *   Linear SVC with TFIDF\n",
        "      *   With Squared_hinged loss ( 0.8065 ) \n",
        "      *   With hinged loss\n",
        "          *    With loss_intercept=True ( 0.8174 )\n",
        "          *    With loss_intercept=False ( 0.8190 )\n",
        "               *    TFIDF( Char ) with n-gram (4-8) ( 0.8229 )\n",
        "\n",
        "Somehow, I got accuracy a bit less when i cleaned the text separately. Although, TFIDF takes care of that. With breakthrough from hinged loss, I started trying different types of TFIDF and it turns out that the best approach was to use char level TFIDF with n gram. I tried varying different values of ngram range.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNAH_4hlkySb",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJTgNktBW5Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhHHfKgbk9eW",
        "colab_type": "text"
      },
      "source": [
        "## Read and Assess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WbXYFWAYJl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b81b0ab9-812f-4fdc-8372-830982a9cd07"
      },
      "source": [
        "df_train=pd.read_csv(\"/content/train.csv\")\n",
        "df_test=pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  ... Quantitative Finance\n",
              "0   1  ...                    0\n",
              "1   2  ...                    0\n",
              "2   3  ...                    0\n",
              "3   4  ...                    0\n",
              "4   5  ...                    0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUUaPtSBlFnb",
        "colab_type": "text"
      },
      "source": [
        "## Extracting what we need\n",
        "\n",
        "Here we have 2 columns that are Abstract and Title. We would need the content of both of these columns for our model to predict the topic. So, i created a new column in the dataframe called text, stored the test ids and deleted the columns ID, ABSTRACT,TITLE from the test and train dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YkKhUcBZFSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "adc8111c-d3fd-4bfe-9a92-6d0ed6178258"
      },
      "source": [
        "df_train[\"text\"]=df_train[\"TITLE\"]+' '+df_train[\"ABSTRACT\"]\n",
        "df_test[\"text\"]=df_test[\"TITLE\"]+' '+df_test[\"ABSTRACT\"]\n",
        "del df_train[\"TITLE\"]\n",
        "del df_train[\"ABSTRACT\"]\n",
        "del df_train[\"ID\"]\n",
        "main_test_ids=df_test[\"ID\"]\n",
        "main_test_title=df_test[\"TITLE\"]\n",
        "main_test_abstract=df_test[\"ABSTRACT\"]\n",
        "del df_test[\"TITLE\"]\n",
        "del df_test[\"ABSTRACT\"]\n",
        "del df_test[\"ID\"]\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Rotation Invariance Neural Network   Rotation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Computer Science  ...                                               text\n",
              "0                 1  ...  Reconstructing Subject-Specific Effect Maps   ...\n",
              "1                 1  ...  Rotation Invariance Neural Network   Rotation ...\n",
              "2                 0  ...  Spherical polyharmonics and Poisson kernels fo...\n",
              "3                 0  ...  A finite element approximation for the stochas...\n",
              "4                 1  ...  Comparative study of Discrete Wavelet Transfor...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2hBuvk8l-C7",
        "colab_type": "text"
      },
      "source": [
        "Extract the main columns by dropping the text. These will be used for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuGovWIxZMJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "05a26084-a76a-4e9b-b028-2ea54cefb017"
      },
      "source": [
        "df_train[\"text\"][1]\n",
        "df_train_classes=df_train.drop(\"text\",axis=1)\n",
        "df_train_classes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Computer Science  Physics  ...  Quantitative Biology  Quantitative Finance\n",
              "0                 1        0  ...                     0                     0\n",
              "1                 1        0  ...                     0                     0\n",
              "2                 0        0  ...                     0                     0\n",
              "3                 0        0  ...                     0                     0\n",
              "4                 1        0  ...                     0                     0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Me6T3bamGNy",
        "colab_type": "text"
      },
      "source": [
        "## Optional Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLZEzecjZOQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def preprocess_text(sen):\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    sentence = re.sub(r\"what's\",\"what is\",sentence)\n",
        "    sentence = re.sub(r\"won't\",\"will not\",sentence)\n",
        "    sentence = re.sub(r\" of \",' ',sentence)\n",
        "    sentence = re.sub(r\" and \",' ',sentence)\n",
        "    sentence = re.sub(r\" in \",' ',sentence)\n",
        "    sentence = re.sub(r\" this \",' ',sentence)\n",
        "    sentence = re.sub(r\" the \",' ',sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlcG0EspZQa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "sentences = list(df_train[\"text\"])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))\n",
        "df_train[\"text\"]=X\n",
        "X=[]\n",
        "sentences = list(df_test[\"text\"])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))\n",
        "df_test[\"text\"]=X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqIPRunyHuAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a5a14c03-b75e-4af0-8c62-52234be19e90"
      },
      "source": [
        "df_train[\"text\"][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Rotation Invariance Neural Network Rotation invariance translation invariance have great values image recognition tasks In paper we bring new architecture convolutional neural network CNN named cyclic convolutional layer to achieve rotation invariance symbol recognition We can also get position orientation symbol by network to achieve detection purpose for multiple non overlap target Last but not least architecture can achieve one shot learning some cases using those invariance '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWLNatamOf2",
        "colab_type": "text"
      },
      "source": [
        "## Splitting into train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkajBVWQZScc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train[\"text\"],df_train_classes, test_size=0.16, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLwSNkvhmZrR",
        "colab_type": "text"
      },
      "source": [
        "## CountVectorizer used only for Naive Bayes only and not for other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuSfxintZU8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(strip_accents=\"ascii\", token_pattern=u\"(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b\", lowercase=True, stop_words=\"english\")\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "X_test_main_cv=cv.transform(df_test[\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr5Ks_zSm-O7",
        "colab_type": "text"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "I have done prediction label by label. made an array of all labels and predicted for each using SVC Model with char of n-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-muWiM3ZXa_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "f4c1cc1f-a149-4b7b-8dac-de172af789e2"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "labels = ['Computer Science', 'Physics', 'Mathematics','Statistics','Quantitative Biology', 'Quantitative Finance']\n",
        "label_predict=[]\n",
        "for label in labels:\n",
        "    text_clf = Pipeline([('tfidf', TfidfVectorizer(min_df=True,smooth_idf=False,sublinear_tf=True,analyzer='char',strip_accents='ascii', ngram_range=(4,8))),\n",
        "                         ('clf',LinearSVC(loss=\"hinge\",fit_intercept=False ,class_weight='balanced')),\n",
        "    ])\n",
        "# LinearSVC(loss=\"hinge\",fit_intercept=False,tol=1e-3)\n",
        "    text_clf.fit(X_train, y_train[label])  \n",
        "# min_df=True,smooth_idf=True,sublinear_tf=True,analyzer='char',strip_accents='ascii',token_pattern=r'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', ngram_range=(4,8)\n",
        "    predictions = text_clf.predict(X_test)\n",
        "\n",
        "#     naive_bayes = MultinomialNB()\n",
        "#     naive_bayes.fit(X_train_cv, y_train[label])\n",
        "#     predictions = naive_bayes.predict(X_test_cv)\n",
        "    \n",
        "    print(\"Accuracy score: \", accuracy_score(y_test[label], predictions))\n",
        "    print(\"Precision score: \", precision_score(y_test[label], predictions))\n",
        "    print(\"Recall score: \", recall_score(y_test[label], predictions))\n",
        "    \n",
        "    final_predict= text_clf.predict(df_test[\"text\"])\n",
        "    print(final_predict)\n",
        "    label_predict.append(np.array(final_predict))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8748510131108462\n",
            "Precision score:  0.8146900269541779\n",
            "Recall score:  0.8929098966026587\n",
            "[0 0 1 ... 1 0 1]\n",
            "Accuracy score:  0.9368295589988082\n",
            "Precision score:  0.9121338912133892\n",
            "Recall score:  0.872\n",
            "[0 1 0 ... 0 0 0]\n",
            "Accuracy score:  0.9055423122765197\n",
            "Precision score:  0.8198689956331878\n",
            "Recall score:  0.831672203765227\n",
            "[0 0 0 ... 0 0 0]\n",
            "Accuracy score:  0.8861740166865316\n",
            "Precision score:  0.7593406593406593\n",
            "Recall score:  0.8091334894613583\n",
            "[1 0 0 ... 0 1 0]\n",
            "Accuracy score:  0.9758641239570918\n",
            "Precision score:  0.6904761904761905\n",
            "Recall score:  0.29896907216494845\n",
            "[0 0 0 ... 0 0 0]\n",
            "Accuracy score:  0.9934445768772348\n",
            "Precision score:  0.9\n",
            "Recall score:  0.47368421052631576\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8QAnvIZZtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9b81ff53-b234-4d7c-a253-e112cd133f1b"
      },
      "source": [
        "label_predict.append(np.array(main_test_ids))\n",
        "for x in label_predict:\n",
        "    print(len(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8989\n",
            "8989\n",
            "8989\n",
            "8989\n",
            "8989\n",
            "8989\n",
            "8989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpYcLBy9Zy-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.DataFrame({'ID':label_predict[6],'Computer Science': label_predict[0],'Physics': label_predict[1],'Mathematics': label_predict[2],'Statistics': label_predict[3],'Quantitative Biology': label_predict[4],'Quantitative Finance': label_predict[5]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvY1ZoUpZ0tH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d48812e8-4848-400e-e1de-4a79a567a644"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20973</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20974</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20975</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20976</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20977</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  Computer Science  ...  Quantitative Biology  Quantitative Finance\n",
              "0  20973                 0  ...                     0                     0\n",
              "1  20974                 0  ...                     0                     0\n",
              "2  20975                 1  ...                     0                     0\n",
              "3  20976                 0  ...                     0                     0\n",
              "4  20977                 1  ...                     0                     0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoEkoOcTZ2Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.to_csv(r'submission.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJM8mbN6hCZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}